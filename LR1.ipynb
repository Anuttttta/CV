{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics kagglehub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vcq06nWA1aTN",
        "outputId": "ea7796a7-158b-4531-e4d3-8b4caaa10997"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.215-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.17-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (25.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.10.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.215-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.17-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.215 ultralytics-thop-2.0.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"phucthaiv02/butterfly-image-classification\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9K9fJnfh1pLV",
        "outputId": "bdf45a89-3e4b-4a24-cbe3-9d06e455bd58"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'butterfly-image-classification' dataset.\n",
            "Path to dataset files: /kaggle/input/butterfly-image-classification\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)\n",
        "!pip install kagglehub -q\n",
        "\n",
        "import kagglehub\n",
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
        "print(\"–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞\")\n",
        "path = kagglehub.dataset_download(\"phucthaiv02/butterfly-image-classification\")\n",
        "print(\"–ü—É—Ç—å –∫ –¥–∞—Ç–∞—Å–µ—Ç—É:\", path)\n",
        "\n",
        "dataset_root = Path(path)\n",
        "\n",
        "# 2. –°–æ–±–∏—Ä–∞–µ–º –í–°–ï –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ –∫–æ—Ä–Ω–µ–≤—ã—Ö –ø–∞–ø–æ–∫-–∫–ª–∞—Å—Å–æ–≤\n",
        "all_images = []\n",
        "all_labels = []\n",
        "\n",
        "# –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º –ø–æ–¥–ø–∞–ø–∫–∞–º –≤ –∫–æ—Ä–Ω–µ ‚Äî –∫–∞–∂–¥–∞—è = –æ—Ç–¥–µ–ª—å–Ω—ã–π –∫–ª–∞—Å—Å\n",
        "for class_dir in dataset_root.iterdir():\n",
        "    if class_dir.is_dir():\n",
        "        class_name = class_dir.name\n",
        "        # –ò—â–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤–Ω—É—Ç—Ä–∏ –ø–∞–ø–∫–∏ –∫–ª–∞—Å—Å–∞\n",
        "        for img_path in class_dir.glob(\"*\"):\n",
        "            if img_path.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp']:\n",
        "                all_images.append(str(img_path))\n",
        "                all_labels.append(class_name)\n",
        "\n",
        "print(f\" –í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–∞–π–¥–µ–Ω–æ: {len(all_images)}\")\n",
        "print(f\" –ö–ª–∞—Å—Å–æ–≤: {len(set(all_labels))}\")\n",
        "\n",
        "if len(all_images) == 0:\n",
        "    raise FileNotFoundError(\" –ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\")\n",
        "\n",
        "# 3. –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É 70/15/15\n",
        "new_dataset_root = Path(\"/content/butterfly_dataset_70_15_15\")\n",
        "shutil.rmtree(new_dataset_root, ignore_errors=True)\n",
        "(new_dataset_root / \"train\").mkdir(parents=True)\n",
        "(new_dataset_root / \"val\").mkdir(parents=True)\n",
        "(new_dataset_root / \"test\").mkdir(parents=True)\n",
        "\n",
        "# 4. –†–∞–∑–±–∏–≤–∞–µ–º —Å–Ω–∞—á–∞–ª–∞ –Ω–∞ train (70%) –∏ –æ—Å—Ç–∞–ª—å–Ω–æ–µ (30%)\n",
        "X_train, X_rest, y_train, y_rest = train_test_split(\n",
        "    all_images, all_labels,\n",
        "    test_size=0.3,\n",
        "    random_state=42,\n",
        "    stratify=all_labels\n",
        ")\n",
        "\n",
        "# –ó–∞—Ç–µ–º –¥–µ–ª–∏–º \"–æ—Å—Ç–∞–ª—å–Ω–æ–µ\" –ø–æ–ø–æ–ª–∞–º ‚Üí 15% val, 15% test\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_rest, y_rest,\n",
        "    test_size=0.5,\n",
        "    random_state=42,\n",
        "    stratify=y_rest\n",
        ")\n",
        "\n",
        "print(f\"\\n–†–∞–∑–º–µ—Ä—ã:\")\n",
        "print(f\"  train: {len(X_train)}\")\n",
        "print(f\"  val:   {len(X_val)}\")\n",
        "print(f\"  test:  {len(X_test)}\")\n",
        "\n",
        "# 5. –§—É–Ω–∫—Ü–∏—è –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è\n",
        "def copy_images(images, labels, split_name):\n",
        "    split_dir = new_dataset_root / split_name\n",
        "    for img_path, label in tqdm(zip(images, labels), total=len(images), desc=f\"–ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ ‚Üí {split_name}\"):\n",
        "        class_dir = split_dir / label\n",
        "        class_dir.mkdir(exist_ok=True)\n",
        "        shutil.copy2(img_path, class_dir / Path(img_path).name)\n",
        "\n",
        "# 6. –ö–æ–ø–∏—Ä—É–µ–º\n",
        "copy_images(X_train, y_train, \"train\")\n",
        "copy_images(X_val, y_val, \"val\")\n",
        "copy_images(X_test, y_test, \"test\")\n",
        "\n",
        "# 7. –°–æ–∑–¥–∞—ë–º YAML –¥–ª—è YOLO\n",
        "classes = sorted(set(all_labels))\n",
        "yaml_content = f\"\"\"path: /content/butterfly_dataset_70_15_15\n",
        "train: train\n",
        "val: val\n",
        "test: test\n",
        "names: {classes}\n",
        "\"\"\"\n",
        "\n",
        "with open(\"/content/butterfly.yaml\", \"w\") as f:\n",
        "    f.write(yaml_content)\n",
        "\n",
        "print(\"\\n –î–∞—Ç–∞—Å–µ—Ç —É—Å–ø–µ—à–Ω–æ –ø–µ—Ä–µ—Å–æ–±—Ä–∞–Ω –≤ —Ñ–æ—Ä–º–∞—Ç–µ 70/15/15!\")\n",
        "print(\" –ü—É—Ç—å:\", new_dataset_root)\n",
        "print(\" YAML:\", \"/content/butterfly.yaml\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fANSFBZ2_My",
        "outputId": "d9bd5216-111f-4ba5-dbbf-38320bb3145b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
            "Using Colab cache for faster access to the 'butterfly-image-classification' dataset.\n",
            "–ü—É—Ç—å –∫ –¥–∞—Ç–∞—Å–µ—Ç—É: /kaggle/input/butterfly-image-classification\n",
            " –í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–∞–π–¥–µ–Ω–æ: 9285\n",
            " –ö–ª–∞—Å—Å–æ–≤: 2\n",
            "\n",
            "–†–∞–∑–º–µ—Ä—ã:\n",
            "  train: 6499\n",
            "  val:   1393\n",
            "  test:  1393\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "–ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ ‚Üí train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6499/6499 [00:14<00:00, 434.37it/s]\n",
            "–ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ ‚Üí val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1393/1393 [00:02<00:00, 464.57it/s]\n",
            "–ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ ‚Üí test: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1393/1393 [00:02<00:00, 516.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " –î–∞—Ç–∞—Å–µ—Ç —É—Å–ø–µ—à–Ω–æ –ø–µ—Ä–µ—Å–æ–±—Ä–∞–Ω –≤ —Ñ–æ—Ä–º–∞—Ç–µ 70/15/15!\n",
            " –ü—É—Ç—å: /content/butterfly_dataset_70_15_15\n",
            " YAML: /content/butterfly.yaml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxWZYHeZ1S7n",
        "outputId": "a61c0fc2-49b0-4f78-fb61-d106ecb209e9"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞...\n",
            "Using Colab cache for faster access to the 'butterfly-image-classification' dataset.\n",
            "–ü—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É –¥–∞—Ç–∞—Å–µ—Ç—É: /kaggle/input/butterfly-image-classification\n",
            "–í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: 9285\n",
            "–ö–ª–∞—Å—Å–æ–≤: 2\n",
            "\n",
            "–†–∞–∑–º–µ—Ä—ã:\n",
            "  train: 6499\n",
            "  val:   1393\n",
            "  test:  1393\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "–ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ ‚Üí train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6499/6499 [00:05<00:00, 1290.49it/s]\n",
            "–ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ ‚Üí val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1393/1393 [00:01<00:00, 1201.09it/s]\n",
            "–ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ ‚Üí test: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1393/1393 [00:01<00:00, 1226.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "–ü—É—Ç—å: /content/butterfly_dataset_70_15_15\n",
            "\n",
            " –ù–∞–π–¥–µ–Ω–æ –∫–ª–∞—Å—Å–æ–≤: 2\n",
            "–ü—Ä–∏–º–µ—Ä—ã: ['test', 'train']\n",
            "\n",
            " –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ yolov8n-cls.pt...\n",
            "\n",
            " –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è...\n",
            "New https://pypi.org/project/ultralytics/8.3.216 available   Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.215 üöÄ Python-3.12.12 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/butterfly_dataset_70_15_15, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n-cls.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=butterfly_yolov8_cls, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/classify/butterfly_yolov8_cls, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/butterfly_dataset_70_15_15/train... found 6499 images in 2 classes    \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/butterfly_dataset_70_15_15/val... found 1393 images in 2 classes    \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /content/butterfly_dataset_70_15_15/test... found 1393 images in 2 classes    \n",
            "Overriding model.yaml nc=1000 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    332802  ultralytics.nn.modules.head.Classify         [256, 2]                      \n",
            "YOLOv8n-cls summary: 56 layers, 1,440,850 parameters, 1,440,850 gradients, 3.4 GFLOPs\n",
            "Transferred 156/158 items from pretrained weights\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access    (ping: 0.0¬±0.0 ms, read: 897.8¬±321.3 MB/s, size: 29.2 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/butterfly_dataset_70_15_15/train... 6499 images, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6499/6499 4.8Kit/s 1.4s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/butterfly_dataset_70_15_15/train.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access    (ping: 0.0¬±0.0 ms, read: 644.0¬±273.9 MB/s, size: 25.3 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/butterfly_dataset_70_15_15/val... 1393 images, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1393/1393 4.6Kit/s 0.3s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/butterfly_dataset_70_15_15/val.cache\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
            "Image sizes 224 train, 224 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/classify/butterfly_yolov8_cls\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       1/30         0G     0.6435          3        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 204/204 0.6it/s 5:53\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 22/22 0.9it/s 23.6s\n",
            "                   all      0.691          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       2/30         0G     0.6344          3        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 204/204 0.6it/s 5:46\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 22/22 1.0it/s 22.5s\n",
            "                   all      0.698          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       3/30         0G     0.6363          3        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 204/204 0.6it/s 5:41\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 22/22 1.0it/s 22.8s\n",
            "                   all      0.696          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       4/30         0G     0.6235          3        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 204/204 0.6it/s 5:40\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 22/22 0.9it/s 24.8s\n",
            "                   all        0.7          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       5/30         0G     0.6221          3        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 204/204 0.6it/s 5:39\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 22/22 0.9it/s 25.4s\n",
            "                   all        0.7          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       6/30         0G     0.6181          3        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 204/204 0.6it/s 5:38\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 22/22 0.9it/s 23.8s\n",
            "                   all        0.7          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       7/30         0G     0.6119          3        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 204/204 0.6it/s 5:39\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 22/22 1.0it/s 22.1s\n",
            "                   all        0.7          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       8/30         0G     0.6104          3        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 204/204 0.6it/s 5:36\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 22/22 1.0it/s 21.8s\n",
            "                   all        0.7          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       9/30         0G     0.6119          3        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 204/204 0.6it/s 5:37\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 22/22 0.9it/s 23.8s\n",
            "                   all        0.7          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      10/30         0G     0.6132          3        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 204/204 0.6it/s 5:37\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 22/22 0.9it/s 24.0s\n",
            "                   all        0.7          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      11/30         0G     0.6121          3        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 204/204 0.6it/s 5:34\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 22/22 0.9it/s 24.3s\n",
            "                   all        0.7          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      12/30         0G     0.6077          3        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 204/204 0.6it/s 5:39\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 22/22 1.0it/s 22.1s\n",
            "                   all        0.7          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      13/30         0G     0.6093          3        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 204/204 0.6it/s 5:36\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 22/22 1.0it/s 22.4s\n",
            "                   all        0.7          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      14/30         0G     0.6059          3        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 204/204 0.6it/s 5:36\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 22/22 1.0it/s 22.0s\n",
            "                   all        0.7          1\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 10 epochs. Best results observed at epoch 4, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=10) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
            "\n",
            "14 epochs completed in 1.410 hours.\n",
            "Optimizer stripped from /content/runs/classify/butterfly_yolov8_cls/weights/last.pt, 3.0MB\n",
            "Optimizer stripped from /content/runs/classify/butterfly_yolov8_cls/weights/best.pt, 3.0MB\n",
            "\n",
            "Validating /content/runs/classify/butterfly_yolov8_cls/weights/best.pt...\n",
            "Ultralytics 8.3.215 üöÄ Python-3.12.12 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
            "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/butterfly_dataset_70_15_15/train... found 6499 images in 2 classes    \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/butterfly_dataset_70_15_15/val... found 1393 images in 2 classes    \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /content/butterfly_dataset_70_15_15/test... found 1393 images in 2 classes    \n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 22/22 1.1it/s 19.9s\n",
            "                   all        0.7          1\n",
            "Speed: 0.0ms preprocess, 12.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/classify/butterfly_yolov8_cls\u001b[0m\n",
            "\n",
            " –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞ val...\n",
            "Ultralytics 8.3.215 üöÄ Python-3.12.12 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
            "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/butterfly_dataset_70_15_15/train... found 6499 images in 2 classes    \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/butterfly_dataset_70_15_15/val... found 1393 images in 2 classes    \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /content/butterfly_dataset_70_15_15/test... found 1393 images in 2 classes    \n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access    (ping: 0.0¬±0.0 ms, read: 336.1¬±163.6 MB/s, size: 25.3 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/butterfly_dataset_70_15_15/val... 1393 images, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1393/1393 2.2Mit/s 0.0s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 4.3it/s 20.7s\n",
            "                   all        0.7          1\n",
            "Speed: 0.0ms preprocess, 12.4ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/classify/val3\u001b[0m\n",
            " Val Top-1 Accuracy: 0.6999\n",
            " Val Top-5 Accuracy: 1.0000\n",
            "\n",
            " –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞ test...\n",
            "Ultralytics 8.3.215 üöÄ Python-3.12.12 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/butterfly_dataset_70_15_15/train... found 6499 images in 2 classes    \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/butterfly_dataset_70_15_15/val... found 1393 images in 2 classes    \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /content/butterfly_dataset_70_15_15/test... found 1393 images in 2 classes    \n",
            "\u001b[34m\u001b[1mtest: \u001b[0mFast image access    (ping: 0.1¬±0.0 ms, read: 179.8¬±72.5 MB/s, size: 25.3 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtest: \u001b[0mScanning /content/butterfly_dataset_70_15_15/test... 1393 images, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1393/1393 3.9Kit/s 0.4s\n",
            "\u001b[34m\u001b[1mtest: \u001b[0mNew cache created: /content/butterfly_dataset_70_15_15/test.cache\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 88/88 4.2it/s 20.7s\n",
            "                   all        0.7          1\n",
            "Speed: 0.0ms preprocess, 12.4ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/classify/val4\u001b[0m\n",
            " Test Top-1 Accuracy: 0.6999\n",
            "\n",
            " –ü—Ä–∏–º–µ—Ä –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è...\n",
            "\n",
            "image 1/1 /content/butterfly_dataset_70_15_15/val/test/Image_1322.jpg: 224x224 train 0.78, test 0.22, 21.1ms\n",
            "Speed: 2.4ms preprocess, 21.1ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "–ò—Å—Ç–∏–Ω–Ω—ã–π –∫–ª–∞—Å—Å: test\n",
            "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: train (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: 0.7775)\n",
            "\n",
            " –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ runs/classify/butterfly_yolov8_cls/\n"
          ]
        }
      ],
      "source": [
        "# 1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π\n",
        "!pip install kagglehub ultralytics -q\n",
        "\n",
        "# 2. –ò–º–ø–æ—Ä—Ç—ã\n",
        "import kagglehub\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# –ß–∞—Å—Ç—å 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
        "\n",
        "print(\" –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞...\")\n",
        "path = kagglehub.dataset_download(\"phucthaiv02/butterfly-image-classification\")\n",
        "dataset_root = Path(path)\n",
        "print(\"–ü—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É –¥–∞—Ç–∞—Å–µ—Ç—É:\", dataset_root)\n",
        "\n",
        "# –°–±–æ—Ä –≤—Å–µ—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –º–µ—Ç–æ–∫\n",
        "SUPPORTED_EXTS = {'.jpg', '.jpeg', '.png', '.bmp'}\n",
        "all_images = []\n",
        "all_labels = []\n",
        "\n",
        "for class_dir in dataset_root.iterdir():\n",
        "    if class_dir.is_dir():\n",
        "        class_name = class_dir.name\n",
        "        for img_path in class_dir.iterdir():\n",
        "            if img_path.suffix.lower() in SUPPORTED_EXTS:\n",
        "                all_images.append(str(img_path))\n",
        "                all_labels.append(class_name)\n",
        "\n",
        "print(f\"–í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(all_images)}\")\n",
        "print(f\"–ö–ª–∞—Å—Å–æ–≤: {len(set(all_labels))}\")\n",
        "\n",
        "if not all_images:\n",
        "    raise FileNotFoundError(\"–ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è!\")\n",
        "\n",
        "# –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã 70/15/15\n",
        "new_dataset_root = Path(\"/content/butterfly_dataset_70_15_15\")\n",
        "shutil.rmtree(new_dataset_root, ignore_errors=True)\n",
        "\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    (new_dataset_root / split).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# –°—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ\n",
        "X_train, X_rest, y_train, y_rest = train_test_split(\n",
        "    all_images, all_labels,\n",
        "    test_size=0.3,\n",
        "    random_state=42,\n",
        "    stratify=all_labels\n",
        ")\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_rest, y_rest,\n",
        "    test_size=0.5,\n",
        "    random_state=42,\n",
        "    stratify=y_rest\n",
        ")\n",
        "\n",
        "print(f\"\\n–†–∞–∑–º–µ—Ä—ã:\")\n",
        "print(f\"  train: {len(X_train)}\")\n",
        "print(f\"  val:   {len(X_val)}\")\n",
        "print(f\"  test:  {len(X_test)}\")\n",
        "\n",
        "# –§—É–Ω–∫—Ü–∏—è –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è\n",
        "def copy_images(images, labels, split_name):\n",
        "    split_dir = new_dataset_root / split_name\n",
        "    for img_path, label in tqdm(zip(images, labels), total=len(images), desc=f\"–ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ ‚Üí {split_name}\"):\n",
        "        class_dir = split_dir / label\n",
        "        class_dir.mkdir(exist_ok=True)\n",
        "        shutil.copy2(img_path, class_dir / Path(img_path).name)\n",
        "\n",
        "# –ö–æ–ø–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ\n",
        "copy_images(X_train, y_train, \"train\")\n",
        "copy_images(X_val, y_val, \"val\")\n",
        "copy_images(X_test, y_test, \"test\")\n",
        "\n",
        "print(\"–ü—É—Ç—å:\", new_dataset_root)\n",
        "\n",
        "# –ß–∞—Å—Ç—å 2: –û–±—É—á–µ–Ω–∏–µ YOLOv8-cls\n",
        "\n",
        "# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã\n",
        "train_dir = new_dataset_root / \"train\"\n",
        "val_dir = new_dataset_root / \"val\"\n",
        "if not (train_dir.exists() and val_dir.exists()):\n",
        "    raise FileNotFoundError(\" –ü–∞–ø–∫–∏ 'train' –∏–ª–∏ 'val' –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç!\")\n",
        "\n",
        "# –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –∫–ª–∞—Å—Å–æ–≤ (–Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è, –Ω–æ –ø–æ–ª–µ–∑–Ω–æ –¥–ª—è –ª–æ–≥–æ–≤)\n",
        "classes = sorted([d.name for d in train_dir.iterdir() if d.is_dir()])\n",
        "print(f\"\\n –ù–∞–π–¥–µ–Ω–æ –∫–ª–∞—Å—Å–æ–≤: {len(classes)}\")\n",
        "print(f\"–ü—Ä–∏–º–µ—Ä—ã: {classes[:5]}\")\n",
        "\n",
        "# –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
        "print(\"\\n –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ yolov8n-cls.pt...\")\n",
        "model = YOLO(\"yolov8n-cls.pt\")\n",
        "\n",
        "# –û–±—É—á–µ–Ω–∏–µ ‚Äî –ü–ï–†–ï–î–ê–Å–ú –ü–£–¢–¨ –ö –ü–ê–ü–ö–ï, –ù–ï –ö YAML!\n",
        "print(\"\\n –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è...\")\n",
        "results = model.train(\n",
        "    data=str(new_dataset_root),  # ‚Üê –í–ê–ñ–ù–û: —ç—Ç–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è, –Ω–µ —Ñ–∞–π–ª!\n",
        "    epochs=30,\n",
        "    imgsz=224,\n",
        "    batch=32,  # —É–º–µ–Ω—å—à–∏—Ç–µ –ø—Ä–∏ –Ω–µ—Ö–≤–∞—Ç–∫–µ –ø–∞–º—è—Ç–∏ GPU\n",
        "    name=\"butterfly_yolov8_cls\",\n",
        "    device=0 if next(model.parameters()).is_cuda else \"cpu\",\n",
        "    patience=10,\n",
        "    exist_ok=True\n",
        ")\n",
        "\n",
        "# –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞ val\n",
        "print(\"\\n –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞ val...\")\n",
        "val_metrics = model.val()\n",
        "print(f\" Val Top-1 Accuracy: {val_metrics.top1:.4f}\")\n",
        "print(f\" Val Top-5 Accuracy: {val_metrics.top5:.4f}\")\n",
        "\n",
        "# –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞ test (–µ—Å–ª–∏ –µ—Å—Ç—å)\n",
        "test_dir = new_dataset_root / \"test\"\n",
        "if test_dir.exists() and any(test_dir.iterdir()):\n",
        "    print(\"\\n –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞ test...\")\n",
        "    test_metrics = model.val(data=str(new_dataset_root), split=\"test\")\n",
        "    print(f\" Test Top-1 Accuracy: {test_metrics.top1:.4f}\")\n",
        "else:\n",
        "    print(\"\\n –¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∏–ª–∏ –ø—É—Å—Ç–∞.\")\n",
        "\n",
        "# –ü—Ä–∏–º–µ—Ä –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
        "print(\"\\n –ü—Ä–∏–º–µ—Ä –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è...\")\n",
        "sample_img = None\n",
        "for class_name in classes[:3]:\n",
        "    class_val_path = val_dir / class_name\n",
        "    if class_val_path.exists():\n",
        "        for f in class_val_path.iterdir():\n",
        "            if f.suffix.lower() in SUPPORTED_EXTS:\n",
        "                sample_img = f\n",
        "                true_class = class_name\n",
        "                break\n",
        "    if sample_img:\n",
        "        break\n",
        "\n",
        "if sample_img:\n",
        "    result = model(str(sample_img))\n",
        "    probs = result[0].probs\n",
        "    pred_class = classes[int(probs.top1)]\n",
        "    conf = float(probs.top1conf)\n",
        "    print(f\"–ò—Å—Ç–∏–Ω–Ω—ã–π –∫–ª–∞—Å—Å: {true_class}\")\n",
        "    print(f\"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {pred_class} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {conf:.4f})\")\n",
        "else:\n",
        "    print(\" –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞.\")\n",
        "\n",
        "print(\"\\n –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ runs/classify/butterfly_yolov8_cls/\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yUj31pjw2L6z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
