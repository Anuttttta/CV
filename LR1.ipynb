{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics kagglehub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vcq06nWA1aTN",
        "outputId": "ea7796a7-158b-4531-e4d3-8b4caaa10997"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.215-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.17-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (25.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.10.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.215-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.17-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.215 ultralytics-thop-2.0.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"phucthaiv02/butterfly-image-classification\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9K9fJnfh1pLV",
        "outputId": "bdf45a89-3e4b-4a24-cbe3-9d06e455bd58"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'butterfly-image-classification' dataset.\n",
            "Path to dataset files: /kaggle/input/butterfly-image-classification\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Установка (если нужно)\n",
        "!pip install kagglehub -q\n",
        "\n",
        "import kagglehub\n",
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 1. Загрузка датасета\n",
        "print(\"Загрузка датасета\")\n",
        "path = kagglehub.dataset_download(\"phucthaiv02/butterfly-image-classification\")\n",
        "print(\"Путь к датасету:\", path)\n",
        "\n",
        "dataset_root = Path(path)\n",
        "\n",
        "# 2. Собираем ВСЕ изображения из корневых папок-классов\n",
        "all_images = []\n",
        "all_labels = []\n",
        "\n",
        "# Проходим по всем подпапкам в корне — каждая = отдельный класс\n",
        "for class_dir in dataset_root.iterdir():\n",
        "    if class_dir.is_dir():\n",
        "        class_name = class_dir.name\n",
        "        # Ищем изображения внутри папки класса\n",
        "        for img_path in class_dir.glob(\"*\"):\n",
        "            if img_path.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp']:\n",
        "                all_images.append(str(img_path))\n",
        "                all_labels.append(class_name)\n",
        "\n",
        "print(f\" Всего изображений найдено: {len(all_images)}\")\n",
        "print(f\" Классов: {len(set(all_labels))}\")\n",
        "\n",
        "if len(all_images) == 0:\n",
        "    raise FileNotFoundError(\" Не найдено ни одного изображения\")\n",
        "\n",
        "# 3. Создаём новую структуру 70/15/15\n",
        "new_dataset_root = Path(\"/content/butterfly_dataset_70_15_15\")\n",
        "shutil.rmtree(new_dataset_root, ignore_errors=True)\n",
        "(new_dataset_root / \"train\").mkdir(parents=True)\n",
        "(new_dataset_root / \"val\").mkdir(parents=True)\n",
        "(new_dataset_root / \"test\").mkdir(parents=True)\n",
        "\n",
        "# 4. Разбиваем сначала на train (70%) и остальное (30%)\n",
        "X_train, X_rest, y_train, y_rest = train_test_split(\n",
        "    all_images, all_labels,\n",
        "    test_size=0.3,\n",
        "    random_state=42,\n",
        "    stratify=all_labels\n",
        ")\n",
        "\n",
        "# Затем делим \"остальное\" пополам → 15% val, 15% test\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_rest, y_rest,\n",
        "    test_size=0.5,\n",
        "    random_state=42,\n",
        "    stratify=y_rest\n",
        ")\n",
        "\n",
        "print(f\"\\nРазмеры:\")\n",
        "print(f\"  train: {len(X_train)}\")\n",
        "print(f\"  val:   {len(X_val)}\")\n",
        "print(f\"  test:  {len(X_test)}\")\n",
        "\n",
        "# 5. Функция копирования\n",
        "def copy_images(images, labels, split_name):\n",
        "    split_dir = new_dataset_root / split_name\n",
        "    for img_path, label in tqdm(zip(images, labels), total=len(images), desc=f\"Копирование → {split_name}\"):\n",
        "        class_dir = split_dir / label\n",
        "        class_dir.mkdir(exist_ok=True)\n",
        "        shutil.copy2(img_path, class_dir / Path(img_path).name)\n",
        "\n",
        "# 6. Копируем\n",
        "copy_images(X_train, y_train, \"train\")\n",
        "copy_images(X_val, y_val, \"val\")\n",
        "copy_images(X_test, y_test, \"test\")\n",
        "\n",
        "# 7. Создаём YAML для YOLO\n",
        "classes = sorted(set(all_labels))\n",
        "yaml_content = f\"\"\"path: /content/butterfly_dataset_70_15_15\n",
        "train: train\n",
        "val: val\n",
        "test: test\n",
        "names: {classes}\n",
        "\"\"\"\n",
        "\n",
        "with open(\"/content/butterfly.yaml\", \"w\") as f:\n",
        "    f.write(yaml_content)\n",
        "\n",
        "print(\"\\n Датасет успешно пересобран в формате 70/15/15!\")\n",
        "print(\" Путь:\", new_dataset_root)\n",
        "print(\" YAML:\", \"/content/butterfly.yaml\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fANSFBZ2_My",
        "outputId": "d9bd5216-111f-4ba5-dbbf-38320bb3145b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Загрузка датасета\n",
            "Using Colab cache for faster access to the 'butterfly-image-classification' dataset.\n",
            "Путь к датасету: /kaggle/input/butterfly-image-classification\n",
            " Всего изображений найдено: 9285\n",
            " Классов: 2\n",
            "\n",
            "Размеры:\n",
            "  train: 6499\n",
            "  val:   1393\n",
            "  test:  1393\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Копирование → train: 100%|██████████| 6499/6499 [00:14<00:00, 434.37it/s]\n",
            "Копирование → val: 100%|██████████| 1393/1393 [00:02<00:00, 464.57it/s]\n",
            "Копирование → test: 100%|██████████| 1393/1393 [00:02<00:00, 516.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Датасет успешно пересобран в формате 70/15/15!\n",
            " Путь: /content/butterfly_dataset_70_15_15\n",
            " YAML: /content/butterfly.yaml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxWZYHeZ1S7n",
        "outputId": "a61c0fc2-49b0-4f78-fb61-d106ecb209e9"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Загрузка датасета...\n",
            "Using Colab cache for faster access to the 'butterfly-image-classification' dataset.\n",
            "Путь к исходному датасету: /kaggle/input/butterfly-image-classification\n",
            "Всего изображений: 9285\n",
            "Классов: 2\n",
            "\n",
            "Размеры:\n",
            "  train: 6499\n",
            "  val:   1393\n",
            "  test:  1393\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Копирование → train: 100%|██████████| 6499/6499 [00:05<00:00, 1290.49it/s]\n",
            "Копирование → val: 100%|██████████| 1393/1393 [00:01<00:00, 1201.09it/s]\n",
            "Копирование → test: 100%|██████████| 1393/1393 [00:01<00:00, 1226.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Путь: /content/butterfly_dataset_70_15_15\n",
            "\n",
            " Найдено классов: 2\n",
            "Примеры: ['test', 'train']\n",
            "\n",
            " Загрузка модели yolov8n-cls.pt...\n",
            "\n",
            " Запуск обучения...\n",
            "New https://pypi.org/project/ultralytics/8.3.216 available 😃 Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.215 🚀 Python-3.12.12 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/butterfly_dataset_70_15_15, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n-cls.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=butterfly_yolov8_cls, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/classify/butterfly_yolov8_cls, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/butterfly_dataset_70_15_15/train... found 6499 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/butterfly_dataset_70_15_15/val... found 1393 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /content/butterfly_dataset_70_15_15/test... found 1393 images in 2 classes ✅ \n",
            "Overriding model.yaml nc=1000 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    332802  ultralytics.nn.modules.head.Classify         [256, 2]                      \n",
            "YOLOv8n-cls summary: 56 layers, 1,440,850 parameters, 1,440,850 gradients, 3.4 GFLOPs\n",
            "Transferred 156/158 items from pretrained weights\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 897.8±321.3 MB/s, size: 29.2 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/butterfly_dataset_70_15_15/train... 6499 images, 0 corrupt: 100% ━━━━━━━━━━━━ 6499/6499 4.8Kit/s 1.4s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/butterfly_dataset_70_15_15/train.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 644.0±273.9 MB/s, size: 25.3 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/butterfly_dataset_70_15_15/val... 1393 images, 0 corrupt: 100% ━━━━━━━━━━━━ 1393/1393 4.6Kit/s 0.3s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/butterfly_dataset_70_15_15/val.cache\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
            "Image sizes 224 train, 224 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/classify/butterfly_yolov8_cls\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       1/30         0G     0.6435          3        224: 100% ━━━━━━━━━━━━ 204/204 0.6it/s 5:53\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 22/22 0.9it/s 23.6s\n",
            "                   all      0.691          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       2/30         0G     0.6344          3        224: 100% ━━━━━━━━━━━━ 204/204 0.6it/s 5:46\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 22/22 1.0it/s 22.5s\n",
            "                   all      0.698          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       3/30         0G     0.6363          3        224: 100% ━━━━━━━━━━━━ 204/204 0.6it/s 5:41\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 22/22 1.0it/s 22.8s\n",
            "                   all      0.696          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       4/30         0G     0.6235          3        224: 100% ━━━━━━━━━━━━ 204/204 0.6it/s 5:40\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 22/22 0.9it/s 24.8s\n",
            "                   all        0.7          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       5/30         0G     0.6221          3        224: 100% ━━━━━━━━━━━━ 204/204 0.6it/s 5:39\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 22/22 0.9it/s 25.4s\n",
            "                   all        0.7          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       6/30         0G     0.6181          3        224: 100% ━━━━━━━━━━━━ 204/204 0.6it/s 5:38\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 22/22 0.9it/s 23.8s\n",
            "                   all        0.7          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       7/30         0G     0.6119          3        224: 100% ━━━━━━━━━━━━ 204/204 0.6it/s 5:39\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 22/22 1.0it/s 22.1s\n",
            "                   all        0.7          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       8/30         0G     0.6104          3        224: 100% ━━━━━━━━━━━━ 204/204 0.6it/s 5:36\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 22/22 1.0it/s 21.8s\n",
            "                   all        0.7          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       9/30         0G     0.6119          3        224: 100% ━━━━━━━━━━━━ 204/204 0.6it/s 5:37\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 22/22 0.9it/s 23.8s\n",
            "                   all        0.7          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      10/30         0G     0.6132          3        224: 100% ━━━━━━━━━━━━ 204/204 0.6it/s 5:37\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 22/22 0.9it/s 24.0s\n",
            "                   all        0.7          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      11/30         0G     0.6121          3        224: 100% ━━━━━━━━━━━━ 204/204 0.6it/s 5:34\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 22/22 0.9it/s 24.3s\n",
            "                   all        0.7          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      12/30         0G     0.6077          3        224: 100% ━━━━━━━━━━━━ 204/204 0.6it/s 5:39\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 22/22 1.0it/s 22.1s\n",
            "                   all        0.7          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      13/30         0G     0.6093          3        224: 100% ━━━━━━━━━━━━ 204/204 0.6it/s 5:36\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 22/22 1.0it/s 22.4s\n",
            "                   all        0.7          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      14/30         0G     0.6059          3        224: 100% ━━━━━━━━━━━━ 204/204 0.6it/s 5:36\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 22/22 1.0it/s 22.0s\n",
            "                   all        0.7          1\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 10 epochs. Best results observed at epoch 4, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=10) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
            "\n",
            "14 epochs completed in 1.410 hours.\n",
            "Optimizer stripped from /content/runs/classify/butterfly_yolov8_cls/weights/last.pt, 3.0MB\n",
            "Optimizer stripped from /content/runs/classify/butterfly_yolov8_cls/weights/best.pt, 3.0MB\n",
            "\n",
            "Validating /content/runs/classify/butterfly_yolov8_cls/weights/best.pt...\n",
            "Ultralytics 8.3.215 🚀 Python-3.12.12 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
            "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/butterfly_dataset_70_15_15/train... found 6499 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/butterfly_dataset_70_15_15/val... found 1393 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /content/butterfly_dataset_70_15_15/test... found 1393 images in 2 classes ✅ \n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 22/22 1.1it/s 19.9s\n",
            "                   all        0.7          1\n",
            "Speed: 0.0ms preprocess, 12.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/classify/butterfly_yolov8_cls\u001b[0m\n",
            "\n",
            " Валидация на val...\n",
            "Ultralytics 8.3.215 🚀 Python-3.12.12 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
            "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/butterfly_dataset_70_15_15/train... found 6499 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/butterfly_dataset_70_15_15/val... found 1393 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /content/butterfly_dataset_70_15_15/test... found 1393 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 336.1±163.6 MB/s, size: 25.3 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/butterfly_dataset_70_15_15/val... 1393 images, 0 corrupt: 100% ━━━━━━━━━━━━ 1393/1393 2.2Mit/s 0.0s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 88/88 4.3it/s 20.7s\n",
            "                   all        0.7          1\n",
            "Speed: 0.0ms preprocess, 12.4ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/classify/val3\u001b[0m\n",
            " Val Top-1 Accuracy: 0.6999\n",
            " Val Top-5 Accuracy: 1.0000\n",
            "\n",
            " Валидация на test...\n",
            "Ultralytics 8.3.215 🚀 Python-3.12.12 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/butterfly_dataset_70_15_15/train... found 6499 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/butterfly_dataset_70_15_15/val... found 1393 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /content/butterfly_dataset_70_15_15/test... found 1393 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest: \u001b[0mFast image access ✅ (ping: 0.1±0.0 ms, read: 179.8±72.5 MB/s, size: 25.3 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtest: \u001b[0mScanning /content/butterfly_dataset_70_15_15/test... 1393 images, 0 corrupt: 100% ━━━━━━━━━━━━ 1393/1393 3.9Kit/s 0.4s\n",
            "\u001b[34m\u001b[1mtest: \u001b[0mNew cache created: /content/butterfly_dataset_70_15_15/test.cache\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 88/88 4.2it/s 20.7s\n",
            "                   all        0.7          1\n",
            "Speed: 0.0ms preprocess, 12.4ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/classify/val4\u001b[0m\n",
            " Test Top-1 Accuracy: 0.6999\n",
            "\n",
            " Пример предсказания...\n",
            "\n",
            "image 1/1 /content/butterfly_dataset_70_15_15/val/test/Image_1322.jpg: 224x224 train 0.78, test 0.22, 21.1ms\n",
            "Speed: 2.4ms preprocess, 21.1ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "Истинный класс: test\n",
            "Предсказание: train (уверенность: 0.7775)\n",
            "\n",
            " Обучение завершено! Модель сохранена в runs/classify/butterfly_yolov8_cls/\n"
          ]
        }
      ],
      "source": [
        "# 1. Установка зависимостей\n",
        "!pip install kagglehub ultralytics -q\n",
        "\n",
        "# 2. Импорты\n",
        "import kagglehub\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Часть 1: Подготовка датасета\n",
        "\n",
        "print(\" Загрузка датасета...\")\n",
        "path = kagglehub.dataset_download(\"phucthaiv02/butterfly-image-classification\")\n",
        "dataset_root = Path(path)\n",
        "print(\"Путь к исходному датасету:\", dataset_root)\n",
        "\n",
        "# Сбор всех изображений и меток\n",
        "SUPPORTED_EXTS = {'.jpg', '.jpeg', '.png', '.bmp'}\n",
        "all_images = []\n",
        "all_labels = []\n",
        "\n",
        "for class_dir in dataset_root.iterdir():\n",
        "    if class_dir.is_dir():\n",
        "        class_name = class_dir.name\n",
        "        for img_path in class_dir.iterdir():\n",
        "            if img_path.suffix.lower() in SUPPORTED_EXTS:\n",
        "                all_images.append(str(img_path))\n",
        "                all_labels.append(class_name)\n",
        "\n",
        "print(f\"Всего изображений: {len(all_images)}\")\n",
        "print(f\"Классов: {len(set(all_labels))}\")\n",
        "\n",
        "if not all_images:\n",
        "    raise FileNotFoundError(\"Не найдено ни одного изображения!\")\n",
        "\n",
        "# Создание новой структуры 70/15/15\n",
        "new_dataset_root = Path(\"/content/butterfly_dataset_70_15_15\")\n",
        "shutil.rmtree(new_dataset_root, ignore_errors=True)\n",
        "\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    (new_dataset_root / split).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Стратифицированное разбиение\n",
        "X_train, X_rest, y_train, y_rest = train_test_split(\n",
        "    all_images, all_labels,\n",
        "    test_size=0.3,\n",
        "    random_state=42,\n",
        "    stratify=all_labels\n",
        ")\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_rest, y_rest,\n",
        "    test_size=0.5,\n",
        "    random_state=42,\n",
        "    stratify=y_rest\n",
        ")\n",
        "\n",
        "print(f\"\\nРазмеры:\")\n",
        "print(f\"  train: {len(X_train)}\")\n",
        "print(f\"  val:   {len(X_val)}\")\n",
        "print(f\"  test:  {len(X_test)}\")\n",
        "\n",
        "# Функция копирования\n",
        "def copy_images(images, labels, split_name):\n",
        "    split_dir = new_dataset_root / split_name\n",
        "    for img_path, label in tqdm(zip(images, labels), total=len(images), desc=f\"Копирование → {split_name}\"):\n",
        "        class_dir = split_dir / label\n",
        "        class_dir.mkdir(exist_ok=True)\n",
        "        shutil.copy2(img_path, class_dir / Path(img_path).name)\n",
        "\n",
        "# Копируем данные\n",
        "copy_images(X_train, y_train, \"train\")\n",
        "copy_images(X_val, y_val, \"val\")\n",
        "copy_images(X_test, y_test, \"test\")\n",
        "\n",
        "print(\"Путь:\", new_dataset_root)\n",
        "\n",
        "# Часть 2: Обучение YOLOv8-cls\n",
        "\n",
        "# Проверка структуры\n",
        "train_dir = new_dataset_root / \"train\"\n",
        "val_dir = new_dataset_root / \"val\"\n",
        "if not (train_dir.exists() and val_dir.exists()):\n",
        "    raise FileNotFoundError(\" Папки 'train' или 'val' отсутствуют!\")\n",
        "\n",
        "# Получение списка классов (необязательно для обучения, но полезно для логов)\n",
        "classes = sorted([d.name for d in train_dir.iterdir() if d.is_dir()])\n",
        "print(f\"\\n Найдено классов: {len(classes)}\")\n",
        "print(f\"Примеры: {classes[:5]}\")\n",
        "\n",
        "# Загрузка предобученной модели классификации\n",
        "print(\"\\n Загрузка модели yolov8n-cls.pt...\")\n",
        "model = YOLO(\"yolov8n-cls.pt\")\n",
        "\n",
        "# Обучение — ПЕРЕДАЁМ ПУТЬ К ПАПКЕ, НЕ К YAML!\n",
        "print(\"\\n Запуск обучения...\")\n",
        "results = model.train(\n",
        "    data=str(new_dataset_root),  # ← ВАЖНО: это директория, не файл!\n",
        "    epochs=30,\n",
        "    imgsz=224,\n",
        "    batch=32,  # уменьшите при нехватке памяти GPU\n",
        "    name=\"butterfly_yolov8_cls\",\n",
        "    device=0 if next(model.parameters()).is_cuda else \"cpu\",\n",
        "    patience=10,\n",
        "    exist_ok=True\n",
        ")\n",
        "\n",
        "# Валидация на val\n",
        "print(\"\\n Валидация на val...\")\n",
        "val_metrics = model.val()\n",
        "print(f\" Val Top-1 Accuracy: {val_metrics.top1:.4f}\")\n",
        "print(f\" Val Top-5 Accuracy: {val_metrics.top5:.4f}\")\n",
        "\n",
        "# Валидация на test (если есть)\n",
        "test_dir = new_dataset_root / \"test\"\n",
        "if test_dir.exists() and any(test_dir.iterdir()):\n",
        "    print(\"\\n Валидация на test...\")\n",
        "    test_metrics = model.val(data=str(new_dataset_root), split=\"test\")\n",
        "    print(f\" Test Top-1 Accuracy: {test_metrics.top1:.4f}\")\n",
        "else:\n",
        "    print(\"\\n Тестовая выборка отсутствует или пуста.\")\n",
        "\n",
        "# Пример предсказания\n",
        "print(\"\\n Пример предсказания...\")\n",
        "sample_img = None\n",
        "for class_name in classes[:3]:\n",
        "    class_val_path = val_dir / class_name\n",
        "    if class_val_path.exists():\n",
        "        for f in class_val_path.iterdir():\n",
        "            if f.suffix.lower() in SUPPORTED_EXTS:\n",
        "                sample_img = f\n",
        "                true_class = class_name\n",
        "                break\n",
        "    if sample_img:\n",
        "        break\n",
        "\n",
        "if sample_img:\n",
        "    result = model(str(sample_img))\n",
        "    probs = result[0].probs\n",
        "    pred_class = classes[int(probs.top1)]\n",
        "    conf = float(probs.top1conf)\n",
        "    print(f\"Истинный класс: {true_class}\")\n",
        "    print(f\"Предсказание: {pred_class} (уверенность: {conf:.4f})\")\n",
        "else:\n",
        "    print(\" Не удалось найти изображение для примера.\")\n",
        "\n",
        "print(\"\\n Обучение завершено! Модель сохранена в runs/classify/butterfly_yolov8_cls/\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yUj31pjw2L6z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}